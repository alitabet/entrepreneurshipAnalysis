{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrepreneurship Regression Model \n",
    "\n",
    "This document presentes the implementation of the Logistic Regression model to evaluate entrepreneurial quality presented by Guzamn And Stern in <em>Where is Silicon Valley?</em> - Science, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements\n",
    "\n",
    "This section contains all the relevant <font color=\"blue\"><b><tt>import</tt></b></font> statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import cross_validation, grid_search, linear_model, metrics\n",
    "from sklearn.utils import column_or_1d\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Split Data\n",
    "\n",
    "We will read the data from a STATA <em>.dta</em> file and store it in a <tt>pandas.DataFrame</tt> object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readDtaValue( dtaString, featNames, outName, yearSplit = 2006, verbose = True):\n",
    "    \"\"\" Read data from file dtaString and return a set\n",
    "            of features and labels for training, testing,\n",
    "            and evaluating.\n",
    "        dtaString = Name of the dta file\n",
    "        featNames = List of feature names to extract from DatFrame\n",
    "        outName = Name of the output feature (labels for training)\n",
    "        yearSplit = The year where train/test and eval split\n",
    "        verbose = if True, function prints the description\n",
    "            of the different DatFrames obtained during the data\n",
    "            extraction process\n",
    "    \"\"\"\n",
    "    # First we use pandas to read data in file dtaString\n",
    "    data = pd.read_stata(dtaString)\n",
    "    if verbose:\n",
    "        print \"-----------------------------------------------------------------------------------\"\n",
    "        print \"Raw data description:\"\n",
    "        print data.describe()\n",
    "    \n",
    "    # Now that we have all the data stored in a DatFrame object, we extract\n",
    "    # the relevant train, test, and eval data into seperates Dataframes\n",
    "    dataTrainFeats = data[(data.incyear <= yearSplit) & (data.sampletrain == 1)]\n",
    "    dataTrainFeats = dataTrainFeats[featNames]\n",
    "\n",
    "    dataTestFeats = data[(data.incyear <= yearSplit) & (data.sampletrain == 0)]\n",
    "    dataTestFeats = dataTestFeats[featNames]\n",
    "\n",
    "    dataEvalFeats = data[(data.incyear > yearSplit)]\n",
    "    dataEvalFeats = dataEvalFeats[featNames]\n",
    "\n",
    "\n",
    "    dataTrainLabels = data[(data.incyear <= yearSplit) & (data.sampletrain == 1)]\n",
    "    dataTrainLabels = dataTrainLabels[outName]\n",
    "\n",
    "    dataTestLabels = data[(data.incyear <= yearSplit) & (data.sampletrain == 0)]\n",
    "    dataTestLabels = dataTestLabels[outName]\n",
    "\n",
    "    dataEvalLabels = data[(data.incyear > yearSplit)]\n",
    "    dataEvalLabels = dataEvalLabels[outName]\n",
    "    \n",
    "    if verbose:\n",
    "        print \"-----------------------------------------------------------------------------------\"\n",
    "        print \"Train data description:\"\n",
    "        print dataTrainFeats.describe()\n",
    "        print \"-----------------------------------------------------------------------------------\"\n",
    "        print \"Test data description:\"\n",
    "        print dataTestFeats.describe()\n",
    "        print \"-----------------------------------------------------------------------------------\"\n",
    "        print \"Eval data description:\"\n",
    "        print dataEvalFeats.describe()\n",
    "        \n",
    "    # Now we convert the values in each DataFrame of feature into a numpy array\n",
    "    # for use in the regression\n",
    "    trainFeats = dataTrainFeats.values\n",
    "    testFeats = dataTestFeats.values\n",
    "    evalFeats = dataEvalFeats.values\n",
    "    \n",
    "    trainLabels = np.ravel(dataTrainLabels.values)\n",
    "    testLabels = np.ravel(dataTestLabels.values)\n",
    "    evalLabels = np.ravel(dataEvalLabels.values)\n",
    "    \n",
    "    # Return the raw DataFrame along with all the features and labels\n",
    "    return data, trainFeats, testFeats, evalFeats, trainLabels, testLabels, evalLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "Raw data description:\n",
      "                dataid          local2           tech2       eponymous  \\\n",
      "count   1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean    7972116.422036        0.152160        0.006317        0.088471   \n",
      "std     6512978.065823        0.359176        0.079227        0.283979   \n",
      "min     1873685.000000        0.000000        0.000000        0.000000   \n",
      "25%     2340719.250000        0.000000        0.000000        0.000000   \n",
      "50%     2809982.500000        0.000000        0.000000        0.000000   \n",
      "75%    15529853.750000        0.000000        0.000000        0.000000   \n",
      "max    15927446.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "              is_corp         incyear           is_DE      words_1or2  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.578265     2006.220064        0.047946        0.137647   \n",
      "std          0.493837        2.992976        0.213652        0.344529   \n",
      "min          0.000000     2001.000000        0.000000        0.000000   \n",
      "25%          0.000000     2004.000000        0.000000        0.000000   \n",
      "50%          1.000000     2006.000000        0.000000        0.000000   \n",
      "75%          1.000000     2009.000000        0.000000        0.000000   \n",
      "max          1.000000     2011.000000        1.000000        1.000000   \n",
      "\n",
      "            trademark       anypatent    DEtestsample         growthz  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.007981        0.005809        0.739783        0.000511   \n",
      "std          0.088977        0.075997        0.438753        0.022590   \n",
      "min          0.000000        0.000000        0.000000        0.000000   \n",
      "25%          0.000000        0.000000        0.000000        0.000000   \n",
      "50%          0.000000        0.000000        1.000000        0.000000   \n",
      "75%          0.000000        0.000000        1.000000        0.000000   \n",
      "max          1.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "          only_patent         only_DE   patent_and_DE           train  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.003454        0.045591        0.002355        0.525630   \n",
      "std          0.058668        0.208596        0.048476        0.499343   \n",
      "min          0.000000        0.000000        0.000000        0.000000   \n",
      "25%          0.000000        0.000000        0.000000        0.000000   \n",
      "50%          0.000000        0.000000        0.000000        1.000000   \n",
      "75%          0.000000        0.000000        0.000000        1.000000   \n",
      "max          1.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "                 test     sampletrain     stategrowth  \n",
      "count  1590370.000000  1590370.000000  1590370.000000  \n",
      "mean         0.474370        0.367941        0.000594  \n",
      "std          0.499343        0.482245        0.005874  \n",
      "min          0.000000        0.000000        0.000015  \n",
      "25%          0.000000        0.000000        0.000040  \n",
      "50%          0.000000        0.000000        0.000092  \n",
      "75%          1.000000        1.000000        0.000244  \n",
      "max          1.000000        1.000000        0.424434  \n",
      "-----------------------------------------------------------------------------------\n",
      "Train data description:\n",
      "           eponymous        is_corp         local2          tech2  \\\n",
      "count  585162.000000  585162.000000  585162.000000  585162.000000   \n",
      "mean        0.100348       0.626117       0.152524       0.006545   \n",
      "std         0.300464       0.483833       0.359528       0.080637   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "          words_1or2      trademark    only_patent        only_DE  \\\n",
      "count  585162.000000  585162.000000  585162.000000  585162.000000   \n",
      "mean        0.134715       0.006855       0.003512       0.043514   \n",
      "std         0.341419       0.082508       0.059157       0.204012   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       patent_and_DE  \n",
      "count  585162.000000  \n",
      "mean        0.002251  \n",
      "std         0.047388  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "-----------------------------------------------------------------------------------\n",
      "Test data description:\n",
      "           eponymous        is_corp         local2          tech2  \\\n",
      "count  250784.000000  250784.000000  250784.000000  250784.000000   \n",
      "mean        0.101031       0.626116       0.150899       0.006444   \n",
      "std         0.301371       0.483834       0.357951       0.080014   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "          words_1or2      trademark    only_patent        only_DE  \\\n",
      "count  250784.000000  250784.000000  250784.000000  250784.000000   \n",
      "mean        0.135196       0.006579       0.003760       0.043372   \n",
      "std         0.341934       0.080846       0.061205       0.203693   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       patent_and_DE  \n",
      "count  250784.000000  \n",
      "mean        0.002420  \n",
      "std         0.049138  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "-----------------------------------------------------------------------------------\n",
      "Eval data description:\n",
      "           eponymous        is_corp         local2          tech2  \\\n",
      "count  754424.000000  754424.000000  754424.000000  754424.000000   \n",
      "mean        0.075084       0.525243       0.152298       0.006097   \n",
      "std         0.263527       0.499363       0.359309       0.077847   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "          words_1or2      trademark    only_patent        only_DE  \\\n",
      "count  754424.000000  754424.000000  754424.000000  754424.000000   \n",
      "mean        0.140737       0.009320       0.003307       0.047939   \n",
      "std         0.347750       0.096088       0.057413       0.213636   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       patent_and_DE  \n",
      "count  754424.000000  \n",
      "mean        0.002415  \n",
      "std         0.049084  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "#label_names = ['eponymous','is_corp','local2','tech2','words_1or2','is_DE']\n",
    "#label_names= ['trademark','anypatent']\n",
    "featNames = ['eponymous','is_corp','local2','tech2','words_1or2','trademark','only_patent','only_DE','patent_and_DE']\n",
    "outName = 'growthz';\n",
    "\n",
    "data, trainFeats, testFeats, evalFeats, trainLabels, testLabels, evalLabels = readDtaValue(\"CA.collapsed.dta\", \n",
    "                                                                                           featNames, outName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Using the <tt>statsmodel</tt> module, we fit a logistic regression on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003292\n",
      "         Iterations 14\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               585162\n",
      "Model:                          Logit   Df Residuals:                   585152\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 15 Sep 2015   Pseudo R-squ.:                  0.3224\n",
      "Time:                        18:23:25   Log-Likelihood:                -1926.5\n",
      "converged:                       True   LL-Null:                       -2843.3\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -1.4317      0.509     -2.812      0.005        -2.430    -0.434\n",
      "x2             1.8111      0.181     10.013      0.000         1.457     2.166\n",
      "x3            -0.9717      0.364     -2.668      0.008        -1.685    -0.258\n",
      "x4             0.6514      0.246      2.652      0.008         0.170     1.133\n",
      "x5             0.4083      0.125      3.257      0.001         0.163     0.654\n",
      "x6             1.6797      0.149     11.308      0.000         1.389     1.971\n",
      "x7             3.2199      0.265     12.156      0.000         2.701     3.739\n",
      "x8             3.5815      0.147     24.328      0.000         3.293     3.870\n",
      "x9             5.2757      0.171     30.892      0.000         4.941     5.610\n",
      "const        -10.1309      0.197    -51.432      0.000       -10.517    -9.745\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model using the training data\n",
    "logitModel = sm.Logit(trainLabels,sm.add_constant(trainFeats, prepend=False))\n",
    "logitResult = logitModel.fit()\n",
    "# The summary function displays the statistics of the regression output \n",
    "print logitResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Results Using the Test Data\n",
    "\n",
    "We compute the probability of growth on the test data and check how well the regression model\n",
    "performs using two measures: Number of growth firms in the top <b>5%</b> and top <b>1%</b> of the test distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 %:  76.36 % of all growth companies\n",
      "Top 1 %:  56.36 % of all growth companies\n"
     ]
    }
   ],
   "source": [
    "# Calculate the regression probability on the test set\n",
    "testProb = logitResult.predict(sm.add_constant(testFeats, prepend=False))\n",
    "\n",
    "featsLabelsTest = np.array([testProb,testLabels])\n",
    "sortedFeats = featsLabelsTest[:,np.argsort(-1*featsLabelsTest[0])]\n",
    "topFive = sortedFeats[:,1:round(0.05*len(sortedFeats[0]))]\n",
    "print \"Top 5 %: \",format(100*(topFive.sum(axis=1)/sortedFeats.sum(axis=1))[1],\".2f\"),\"% of all growth companies\"\n",
    "\n",
    "topOne = sortedFeats[:,1:round(0.01*len(sortedFeats[0]))]\n",
    "print \"Top 1 %: \",format(100*(topOne.sum(axis=1)/sortedFeats.sum(axis=1))[1],\".2f\"),\"% of all growth companies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrepreneurship Quality by City\n",
    "\n",
    "Given a a .dta file with valid city names, we extract the city names and look only at the data\n",
    "belonging to these valid cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "Top 20 cities:\n",
      "                       growth\n",
      "city                         \n",
      "MENLO PARK           4.636908\n",
      "MOUNTAIN VIEW        4.447135\n",
      "PALO ALTO            4.396403\n",
      "SUNNYVALE            3.858401\n",
      "REDWOOD CITY         3.784624\n",
      "EAST PALO ALTO       3.373497\n",
      "EMERYVILLE           3.250754\n",
      "PORTOLA VALLEY       2.680680\n",
      "GROVER BEACH         2.424233\n",
      "SAN MATEO            2.330189\n",
      "SOUTH SAN FRANCISCO  2.278259\n",
      "LOS ALTOS HILLS      2.260529\n",
      "LOS ALTOS            2.224483\n",
      "WOODSIDE             2.125992\n",
      "GOLETA               2.114936\n",
      "SANTA CLARA          2.056838\n",
      "FOSTER CITY          1.978786\n",
      "CUPERTINO            1.873815\n",
      "SCOTTS VALLEY        1.737829\n",
      "-----------------------------------------------------------------------------------\n",
      "Mean =  0.437\n",
      "Mean of top 1% =  4.335\n"
     ]
    }
   ],
   "source": [
    "populationString = \"population.dta\" # name of city name file\n",
    "# Predict the growth probabilities on the evaluation data\n",
    "# and extract the data relevant to valid cities only\n",
    "cities = pd.read_stata(populationString)['city'].values # list of valid cities\n",
    "evalProb = logitResult.predict(sm.add_constant(evalFeats, prepend=False)) # probability of growth for eval set\n",
    "\n",
    "# Group probabilities by city (using only valid cities)\n",
    "# and calculate the mean of each city. Final result stored\n",
    "# in ascending order\n",
    "evalResults = pd.DataFrame({'city': data[(data.incyear > 2006)][['city']].values[:,0],\n",
    "                            'growth' : evalProb})\n",
    "evalResults = evalResults[evalResults['city'].isin(cities)].groupby(['city']) \\\n",
    "                                             .mean() \\\n",
    "                                             .apply(lambda x : 1000*x) \\\n",
    "                                             .sort(columns=['growth'], ascending=False)\n",
    "\n",
    "# Print the top 20 cities\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print \"Top 20 cities:\"\n",
    "print evalResults[0:19]\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print \"Mean = \",format(np.mean(evalResults.values), \".3f\")\n",
    "print \"Mean of top 1% = \",format(np.mean(evalResults[0:int(0.01*len(evalResults))].values), \".3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrepreneurship Quality by ZIP Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "Top 20 ZIP Codes:\n",
      "                growth\n",
      "zipcode               \n",
      "92008-4410  328.950844\n",
      "94608-2405  277.670577\n",
      "95154-4976  277.670577\n",
      "94063-1415   83.736493\n",
      "94062-2446   83.736493\n",
      "92630-4785   83.736493\n",
      "92075-2081   83.736493\n",
      "94080-7014   83.736493\n",
      "92052-5568   66.873318\n",
      "95054-1509   66.873318\n",
      "95118-3010   66.873318\n",
      "95035-7409   66.873318\n",
      "95032-2550   66.873318\n",
      "94022-2706   66.873318\n",
      "93100        66.873318\n",
      "94403-1171   66.873318\n",
      "93880        66.873318\n",
      "92130-2040   66.873318\n",
      "93279-0071   65.971165\n",
      "-----------------------------------------------------------------------------------\n",
      "Mean =  0.580\n",
      "Mean of top 1% =  28.788\n"
     ]
    }
   ],
   "source": [
    "# Predict the growth probabilities on the evaluation data\n",
    "# and extract the data relevant to ZIP Codes\n",
    "zipCodes = np.concatenate((pd.read_stata(\"zips.CA.corp.dta\")['zipcode'].values,\\\n",
    "                           pd.read_stata(\"zips.CA.llc.dta\")['zipcode'].values))\n",
    "\n",
    "evalProb = logitResult.predict(sm.add_constant(evalFeats, prepend=False))\n",
    "zipResults = pd.DataFrame({'zipcode': zipCodes, \\\n",
    "                           'growth': evalProb})\n",
    "\n",
    "# Group probabilities by ZIP Code and calculate \n",
    "# the mean of each ZIP Code. Final result stored\n",
    "# in ascending order\n",
    "zipResults = zipResults.groupby(['zipcode'])\\\n",
    "                       .mean() \\\n",
    "                       .apply(lambda x : 1000*x) \\\n",
    "                       .sort(columns=['growth'], ascending=False)\n",
    "        \n",
    "# Print the top 20 cities\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print \"Top 20 ZIP Codes:\"\n",
    "print zipResults[0:19]\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print \"Mean = \",format(np.mean(zipResults.values), \".3f\")\n",
    "print \"Mean of top 1% = \",format(np.mean(zipResults.values[0:int(0.01*len(zipResults))]), \".3f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

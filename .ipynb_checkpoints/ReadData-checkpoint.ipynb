{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read STATA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dataid          local2           tech2       eponymous  \\\n",
      "count   1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean    7972116.422036        0.152160        0.006317        0.088471   \n",
      "std     6512978.065823        0.359176        0.079227        0.283979   \n",
      "min     1873685.000000        0.000000        0.000000        0.000000   \n",
      "25%     2340719.250000        0.000000        0.000000        0.000000   \n",
      "50%     2809982.500000        0.000000        0.000000        0.000000   \n",
      "75%    15529853.750000        0.000000        0.000000        0.000000   \n",
      "max    15927446.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "              is_corp         incyear           is_DE      words_1or2  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.578265     2006.220064        0.047946        0.137647   \n",
      "std          0.493837        2.992976        0.213652        0.344529   \n",
      "min          0.000000     2001.000000        0.000000        0.000000   \n",
      "25%          0.000000     2004.000000        0.000000        0.000000   \n",
      "50%          1.000000     2006.000000        0.000000        0.000000   \n",
      "75%          1.000000     2009.000000        0.000000        0.000000   \n",
      "max          1.000000     2011.000000        1.000000        1.000000   \n",
      "\n",
      "            trademark       anypatent    DEtestsample         growthz  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.007981        0.005809        0.739783        0.000511   \n",
      "std          0.088977        0.075997        0.438753        0.022590   \n",
      "min          0.000000        0.000000        0.000000        0.000000   \n",
      "25%          0.000000        0.000000        0.000000        0.000000   \n",
      "50%          0.000000        0.000000        1.000000        0.000000   \n",
      "75%          0.000000        0.000000        1.000000        0.000000   \n",
      "max          1.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "          only_patent         only_DE   patent_and_DE           train  \\\n",
      "count  1590370.000000  1590370.000000  1590370.000000  1590370.000000   \n",
      "mean         0.003454        0.045591        0.002355        0.525630   \n",
      "std          0.058668        0.208596        0.048476        0.499343   \n",
      "min          0.000000        0.000000        0.000000        0.000000   \n",
      "25%          0.000000        0.000000        0.000000        0.000000   \n",
      "50%          0.000000        0.000000        0.000000        1.000000   \n",
      "75%          0.000000        0.000000        0.000000        1.000000   \n",
      "max          1.000000        1.000000        1.000000        1.000000   \n",
      "\n",
      "                 test     sampletrain     stategrowth  \n",
      "count  1590370.000000  1590370.000000  1590370.000000  \n",
      "mean         0.474370        0.367941        0.000594  \n",
      "std          0.499343        0.482245        0.005874  \n",
      "min          0.000000        0.000000        0.000015  \n",
      "25%          0.000000        0.000000        0.000040  \n",
      "50%          0.000000        0.000000        0.000092  \n",
      "75%          1.000000        1.000000        0.000244  \n",
      "max          1.000000        1.000000        0.424434  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_stata(\"CA.collapsed.dta\")\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           eponymous        is_corp         local2          tech2  \\\n",
      "count  585162.000000  585162.000000  585162.000000  585162.000000   \n",
      "mean        0.100348       0.626117       0.152524       0.006545   \n",
      "std         0.300464       0.483833       0.359528       0.080637   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "          words_1or2      trademark    only_patent        only_DE  \\\n",
      "count  585162.000000  585162.000000  585162.000000  585162.000000   \n",
      "mean        0.134715       0.006855       0.003512       0.043514   \n",
      "std         0.341419       0.082508       0.059157       0.204012   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       patent_and_DE  \n",
      "count  585162.000000  \n",
      "mean        0.002251  \n",
      "std         0.047388  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "-----------------------------------------------------------------------------------\n",
      "count    585162.000000\n",
      "mean          0.000574\n",
      "std           0.023956\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: growthz, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#label_names = ['eponymous','is_corp','local2','tech2','words_1or2','is_DE']\n",
    "#label_names= ['trademark','anypatent']\n",
    "label_names = ['eponymous','is_corp','local2','tech2','words_1or2','trademark','only_patent','only_DE','patent_and_DE']\n",
    "#data_reg = data[label_names + ['sampletrain']]\n",
    "#labels_reg = data[['growthz'] + ['sampletrain']]\n",
    "out_name = 'growthz';\n",
    "\n",
    "data_train_feat = data[(data.incyear <= 2006) & (data.sampletrain == 1)]\n",
    "data_train_feat = data_train_feat[label_names]\n",
    "\n",
    "data_test_feat = data[(data.incyear <= 2006) & (data.sampletrain == 0)]\n",
    "data_test_feat = data_test_feat[label_names]\n",
    "\n",
    "data_eval_feat = data[(data.incyear > 2006)]\n",
    "data_eval_feat = data_eval_feat[label_names]\n",
    "\n",
    "\n",
    "data_train_labels = data[(data.incyear <= 2006) & (data.sampletrain == 1)]\n",
    "data_train_labels = data_train_labels[out_name]\n",
    "\n",
    "data_test_labels = data[(data.incyear <= 2006) & (data.sampletrain == 0)]\n",
    "data_test_labels = data_test_labels[out_name]\n",
    "\n",
    "data_eval_labels = data[(data.incyear > 2006)]\n",
    "data_eval_labels = data_eval_labels[out_name]\n",
    "\n",
    "print data_train_feat.describe()\n",
    "#print \"-----------------------------------------------------------------------------------\"\n",
    "#print data_eval_feat.describe()\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print data_train_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, grid_search, linear_model, metrics\n",
    "from sklearn.utils import column_or_1d\n",
    "#from sklearn import grid_search\n",
    "#from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "features_train = data_train_feat.values\n",
    "features_test = data_test_feat.values\n",
    "features_eval = data_eval_feat.values\n",
    "labels_train = np.ravel(data_train_labels.values)\n",
    "labels_test = np.ravel(data_test_labels.values)\n",
    "labels_eval = np.ravel(data_eval_labels.values)\n",
    "\n",
    "#features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(\n",
    "#    data_train_feat.values, np.ravel(data_train_labels.values), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003292\n",
      "         Iterations 14\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               585162\n",
      "Model:                          Logit   Df Residuals:                   585152\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 15 Sep 2015   Pseudo R-squ.:                  0.3224\n",
      "Time:                        14:32:29   Log-Likelihood:                -1926.5\n",
      "converged:                       True   LL-Null:                       -2843.3\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -1.4317      0.509     -2.812      0.005        -2.430    -0.434\n",
      "x2             1.8111      0.181     10.013      0.000         1.457     2.166\n",
      "x3            -0.9717      0.364     -2.668      0.008        -1.685    -0.258\n",
      "x4             0.6514      0.246      2.652      0.008         0.170     1.133\n",
      "x5             0.4083      0.125      3.257      0.001         0.163     0.654\n",
      "x6             1.6797      0.149     11.308      0.000         1.389     1.971\n",
      "x7             3.2199      0.265     12.156      0.000         2.701     3.739\n",
      "x8             3.5815      0.147     24.328      0.000         3.293     3.870\n",
      "x9             5.2757      0.171     30.892      0.000         4.941     5.610\n",
      "const        -10.1309      0.197    -51.432      0.000       -10.517    -9.745\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logitModel = sm.Logit(labels_train,sm.add_constant(features_train, prepend=False))\n",
    "logitResult = logitModel.fit()\n",
    "\n",
    "print logitResult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000606785369558\n",
      "0.00602014562795\n",
      "0.00908859974132\n"
     ]
    }
   ],
   "source": [
    "print np.mean(logitResult.predict(sm.add_constant(features_eval, prepend=False)))\n",
    "print np.std(logitResult.predict(sm.add_constant(features_eval, prepend=False)))\n",
    "print np.percentile(logitResult.predict(sm.add_constant(features_eval, prepend=False)),99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exponents = np.linspace(0,10,11)\n",
    "#print [10**x for x in exponents] \n",
    "#parameters = {'C':[1, 10]}\n",
    "#clf = linear_model.LogisticRegressionCV(Cs=[10**x for x in exponents])\n",
    "clf = linear_model.LogisticRegression(C=10000000,dual=False,solver='lbfgs')\n",
    "clf.fit(features_train,labels_train)\n",
    "\n",
    "#clf.fit(data_train_feat.values, np.ravel(data_train_labels.values))\n",
    "#print clf.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eponymous   -1.43188581483\n",
      "words_1or2   0.408266807774\n",
      "local2   -0.97169595215\n",
      "tech2   0.651534904643\n",
      "is_corp   1.81110554763\n",
      "trademark   1.67973944928\n",
      "only_patent   3.21988681708\n",
      "only_DE   3.58143932047\n",
      "patent_and_DE   5.27559264479\n",
      "Intercept  -10.1308618376\n",
      "-----------------------------------------------------------------------------------\n",
      "Score  -19.1725122834\n"
     ]
    }
   ],
   "source": [
    "count = 0;\n",
    "for name in label_names:\n",
    "    print name,\" \", clf.coef_[0][count]\n",
    "    count += 1\n",
    "\n",
    "print \"Intercept \",clf.intercept_[0]\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "\n",
    "print \"Score \",metrics.r2_score(clf.predict_proba(features_test)[:,1],labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "                   0\n",
      "count  250784.000000\n",
      "mean        0.000568\n",
      "std         0.005570\n",
      "min         0.000015\n",
      "25%         0.000040\n",
      "50%         0.000092\n",
      "75%         0.000244\n",
      "max         0.328951\n",
      "0    0.000092\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------------------------\n",
      "76.3636363636\n",
      "-----------------------------------------------------------------------------------\n",
      "56.3636363636\n"
     ]
    }
   ],
   "source": [
    "prob_test = logitResult.predict(sm.add_constant(features_test, prepend=False))#clf.predict_proba(features_test)\n",
    "probDataTest = pandas.DataFrame(prob_test)#(prob_test[:,1])\n",
    "\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print probDataTest.describe()\n",
    "print probDataTest.median()\n",
    "\n",
    "featsLabelsTest = np.array([prob_test,labels_test])\n",
    "sortedFeats = featsLabelsTest[:,np.argsort(-1*featsLabelsTest[0])]\n",
    "topFive = sortedFeats[:,1:round(0.05*len(sortedFeats[0]))]\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print 100*(topFive.sum(axis=1)/sortedFeats.sum(axis=1))[1]\n",
    "\n",
    "topOne = sortedFeats[:,1:round(0.01*len(sortedFeats[0]))]\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print 100*(topOne.sum(axis=1)/sortedFeats.sum(axis=1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "count  754424.000000\n",
      "mean        0.000607\n",
      "std         0.006020\n",
      "min         0.000015\n",
      "25%         0.000040\n",
      "50%         0.000060\n",
      "75%         0.000244\n",
      "max         0.424434\n",
      "0    0.00006\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------------------------\n",
      "[[ -2.43586875e-04]\n",
      " [ -2.43586875e-04]\n",
      " [ -3.66386102e-04]\n",
      " ..., \n",
      " [ -3.98273914e-05]\n",
      " [ -3.98273914e-05]\n",
      " [ -3.98273914e-05]]\n",
      "-----------------------------------------------------------------------------------\n",
      "[[ -4.24434050e-01]\n",
      " [ -4.24434050e-01]\n",
      " [ -4.24434050e-01]\n",
      " ..., \n",
      " [ -1.50729302e-05]\n",
      " [ -1.50729302e-05]\n",
      " [ -1.50729302e-05]]\n",
      "-----------------------------------------------------------------------------------\n",
      "                 0\n",
      "count  7543.000000\n",
      "mean      0.034267\n",
      "std       0.048783\n",
      "min       0.009089\n",
      "25%       0.012997\n",
      "50%       0.012997\n",
      "75%       0.045474\n",
      "max       0.424434\n",
      "0    0.012997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features_all = np.concatenate((features_test, features_train, features_eval))\n",
    "\n",
    "prob = logitResult.predict(sm.add_constant(features_eval, prepend=False))#clf.predict_proba(features_eval)\n",
    "probData = pandas.DataFrame(prob)\n",
    "print probData.describe()\n",
    "print probData.median()\n",
    "\n",
    "probDataOnePerc = -1.0*probData.values\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print probDataOnePerc\n",
    "probDataOnePerc.sort(axis=0)\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print probDataOnePerc\n",
    "topOne = pandas.DataFrame(-1*probDataOnePerc[1:round(0.01*len(features_eval))])\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print topOne.describe()\n",
    "print topOne.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             growthz\n",
      "count  754424.000000\n",
      "mean        0.000607\n",
      "std         0.006020\n",
      "min         0.000015\n",
      "25%         0.000040\n",
      "50%         0.000060\n",
      "75%         0.000244\n",
      "max         0.424434\n"
     ]
    }
   ],
   "source": [
    "population_data = pandas.read_stata(\"population.dta\")\n",
    "cities = population_data['city'].values\n",
    "data_eval_feat_city = data[(data.incyear > 2006)]\n",
    "data_eval_feat_city = pandas.DataFrame({'city': data_eval_feat_city[['city']].values[:,0],\n",
    "                                        'growthz' : probData.values[:,0]})#pandas.concat([data_eval_feat_city[['city']], probData],axis=1)\n",
    "\n",
    "print data_eval_feat_city.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          city   growthz\n",
      "0                     SAN JOSE  0.000244\n",
      "1                    PALO ALTO  0.000244\n",
      "2                      HAYWARD  0.000366\n",
      "3                     GLENDALE  0.000244\n",
      "4                       IRVINE  0.000244\n",
      "5                    CUPERTINO  0.000244\n",
      "7                       TUSTIN  0.000244\n",
      "8                       IRVINE  0.000244\n",
      "9                     MILLBRAE  0.000244\n",
      "10                     ARCADIA  0.000244\n",
      "11                 LOS ANGELES  0.000244\n",
      "12                    SAN JOSE  0.000092\n",
      "13                      TUSTIN  0.000244\n",
      "14                  LONG BEACH  0.000244\n",
      "15                   LANCASTER  0.000366\n",
      "16                    SAN JOSE  0.000244\n",
      "17                      TUSTIN  0.000366\n",
      "18                  LONG BEACH  0.000244\n",
      "19                      FRESNO  0.000244\n",
      "20                      GOLETA  0.000092\n",
      "21                        NAPA  0.000244\n",
      "22                    WILDOMAR  0.000092\n",
      "23                    TORRANCE  0.000244\n",
      "24               SAN FRANCISCO  0.000366\n",
      "25                  SANTA CRUZ  0.000092\n",
      "26                    REDLANDS  0.000022\n",
      "27                    ROSEMEAD  0.000244\n",
      "28                   SAN DIEGO  0.000244\n",
      "29                  BUENA PARK  0.000092\n",
      "30                 ALISO VIEJO  0.000244\n",
      "...                        ...       ...\n",
      "754389               SAN DIEGO  0.001429\n",
      "754390  RANCHO SANTA MARGARITA  0.000040\n",
      "754391           BEVERLY HILLS  0.000040\n",
      "754392               RIVERSIDE  0.000040\n",
      "754394     RANCHO PALOS VERDES  0.000040\n",
      "754396             YORBA LINDA  0.000040\n",
      "754397              MENLO PARK  0.000040\n",
      "754398              LONG BEACH  0.000040\n",
      "754399              SACRAMENTO  0.000040\n",
      "754400             LOS ANGELES  0.000040\n",
      "754402             LOS ANGELES  0.000040\n",
      "754403              SACRAMENTO  0.000040\n",
      "754404               CALABASAS  0.000040\n",
      "754406                 OAKLAND  0.000040\n",
      "754407             LOS ANGELES  0.001429\n",
      "754408                 LA MESA  0.000040\n",
      "754409             LOS ANGELES  0.000040\n",
      "754410                CARLSBAD  0.001429\n",
      "754411               SAN DIEGO  0.000040\n",
      "754412               SAN DIEGO  0.000040\n",
      "754413               SANTA ANA  0.000040\n",
      "754414                  IRVINE  0.000996\n",
      "754415                  EXETER  0.000040\n",
      "754416             ALISO VIEJO  0.000040\n",
      "754417                  FOLSOM  0.000040\n",
      "754419                   POWAY  0.000040\n",
      "754420              BUENA PARK  0.000060\n",
      "754421               SAN DIEGO  0.000040\n",
      "754422              SANTA ROSA  0.000040\n",
      "754423                 SHAFTER  0.000040\n",
      "\n",
      "[641742 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "data_city_clean = data_eval_feat_city[data_eval_feat_city['city'].isin(cities)]\n",
    "print data_city_clean\n",
    "#for city in cities:\n",
    "#    tempFrame = data_eval_feat_city[data_eval_feat_city.city == city]\n",
    "#    temp.append(tempFrame.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           growthz\n",
      "count  4302.000000\n",
      "mean      0.004396\n",
      "std       0.016052\n",
      "min       0.000015\n",
      "25%       0.000040\n",
      "50%       0.000244\n",
      "75%       0.001429\n",
      "max       0.277671\n",
      "-----------------------------------------------------------------------------------\n",
      "           growthz\n",
      "count  2106.000000\n",
      "mean      0.004447\n",
      "std       0.016999\n",
      "min       0.000015\n",
      "25%       0.000040\n",
      "50%       0.000244\n",
      "75%       0.000467\n",
      "max       0.277671\n",
      "-----------------------------------------------------------------------------------\n",
      "          growthz\n",
      "count  482.000000\n",
      "mean     0.000437\n",
      "std      0.000593\n",
      "min      0.000051\n",
      "25%      0.000160\n",
      "50%      0.000234\n",
      "75%      0.000451\n",
      "max      0.004637\n",
      "growthz    0.003452\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print data_city_clean.groupby(['city']).get_group('PALO ALTO').describe()\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print data_city_clean.groupby(['city']).get_group('MOUNTAIN VIEW').describe()\n",
    "print \"-----------------------------------------------------------------------------------\"\n",
    "print data_city_clean.groupby(['city']).mean().describe()\n",
    "print data_city_clean.groupby(['city']).mean().quantile(0.99)\n",
    "\n",
    "print \"-----------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      growthz\n",
      "city                         \n",
      "MENLO PARK           4.636908\n",
      "MOUNTAIN VIEW        4.447135\n",
      "PALO ALTO            4.396403\n",
      "SUNNYVALE            3.858401\n",
      "REDWOOD CITY         3.784624\n",
      "EAST PALO ALTO       3.373497\n",
      "EMERYVILLE           3.250754\n",
      "PORTOLA VALLEY       2.680680\n",
      "GROVER BEACH         2.424233\n",
      "SAN MATEO            2.330189\n",
      "SOUTH SAN FRANCISCO  2.278259\n",
      "LOS ALTOS HILLS      2.260529\n",
      "LOS ALTOS            2.224483\n",
      "WOODSIDE             2.125992\n",
      "GOLETA               2.114936\n",
      "SANTA CLARA          2.056838\n",
      "FOSTER CITY          1.978786\n",
      "CUPERTINO            1.873815\n",
      "SCOTTS VALLEY        1.737829\n",
      "SAN FRANCISCO        1.649697\n",
      "BURLINGAME           1.614657\n",
      "CARMEL-BY-THE-SEA    1.588041\n",
      "TRINIDAD             1.505401\n",
      "FREMONT              1.468877\n",
      "SAN BRUNO            1.464017\n",
      "LARKSPUR             1.435745\n",
      "ATHERTON             1.368214\n",
      "BELVEDERE            1.355766\n",
      "SAN CARLOS           1.298759\n",
      "ALISO VIEJO          1.283176\n",
      "...                       ...\n",
      "SOLEDAD              0.104369\n",
      "CLOVERDALE           0.103960\n",
      "PORTOLA              0.103751\n",
      "PARLIER              0.102764\n",
      "FERNDALE             0.102472\n",
      "ORLAND               0.101334\n",
      "TWENTYNINE PALMS     0.100674\n",
      "HIDDEN HILLS         0.099945\n",
      "SHAFTER              0.098245\n",
      "GUSTINE              0.096923\n",
      "RIO DELL             0.096880\n",
      "TULELAKE             0.094238\n",
      "YREKA                0.093235\n",
      "BIGGS                0.091557\n",
      "WHEATLAND            0.089612\n",
      "FORT JONES           0.087476\n",
      "HURON                0.086832\n",
      "ANGELS CAMP          0.084021\n",
      "MENDOTA              0.081881\n",
      "DOS PALOS            0.081842\n",
      "AMADOR CITY          0.080579\n",
      "MARICOPA             0.079645\n",
      "COLUSA               0.077967\n",
      "FIREBAUGH            0.076901\n",
      "WILLOWS              0.072120\n",
      "ISLETON              0.069534\n",
      "NEEDLES              0.069331\n",
      "CALIPATRIA           0.066453\n",
      "DORRIS               0.066013\n",
      "LOYALTON             0.051325\n",
      "\n",
      "[482 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "val = np.reshape(data_city_clean.groupby(['city']).mean().values,len(data_city_clean.groupby(['city']).groups.keys()))\n",
    "byCity = np.reshape(np.array([data_city_clean.groupby(['city']).groups.keys()]),len(data_city_clean.groupby(['city']).groups.keys()))\n",
    "\n",
    "cityData = data_city_clean.groupby(['city']).mean().apply(lambda x:1000*x)\n",
    "print cityData.sort(columns=['growthz'], ascending=False)\n",
    "#cityDict.update({n: np.mean(cityDict[n]) for n in cityDict.keys()})\n",
    "\n",
    "#sortedcityDict = sorted(cityDict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "#print sortedcityDict\n",
    "\n",
    "#idxs = np.argsort(-1*val)\n",
    "#for idx in idxs:\n",
    "#    print byCity[idx],\"\\t\",val[idx]\n",
    "#sortedByCity = byCity[np.argsort(-1*val)]\n",
    "#sortedVal = 1000*val[np.argsort(-1*val)]\n",
    "#print sortedByCity, sortedVal\n",
    "#sortedFeats = featsLabelsTest[:,np.argsort(-1*featsLabelsTest[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
